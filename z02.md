# テック系ZUKKOKE議論第2回

こんなことがありました
（正確に言うと、似たようなことがあったはずですが、
すぐに出てこないので、記憶を頼りに書いている部分もあります）。

どうしたら防げる、あるいは事前に気付けるでしょうか？？
自分事として、そのような予防策をたくさん考えられるといいですね。


## File 5: メールを自動送信したが、2通目以降届かなかった

特定のURLに機械的にアクセスするのが簡単であるように、
特定のアドレスに、特定の件名や内容のメールを機械的に送るのは簡単である。

とある自分が作ったシステムだが、
どうも長く使い続けているとうまく動かなくなるときがあることがわかった。
原因がすぐには特定できず、時間もなく、また、立ち上げ直せばまた正常に動くようになるので、
とりあえずは「不具合が発生したのを気付けるようにし、手動で対応する」ことを考えた。
そこで、別のサーバから定期的にアクセスして、正しく動いているかをチェックし、
動いていなければチームのメーリングリスト宛てにアラートを飛ばすという暫定対応をした。

（あるいは、「1年に1回、認証用の証明書を更新しなければいけないが、忘れそうなので、期限をチェックし、期限が近づいてきたらアラートを飛ばすようにした」みたいなケースでもよい。）

1回目はきちんと届いた。しかし、放置していたら2通目が届くはずなのに来ない。
当然、メールを送るプログラムは変えていない。
何故だろうかと思って調べたら、
まったく同じメールをメーリングリストに送ると弾かれるようになっていることがわかった。

（「弾くなんて」と思うかもしれませんが、そんなものです。）


## File 6: 大量のユーザにメールを送ったが、他のユーザのアドレスが見えていた

BtoSでは無料会員や有料会員向けに送る一斉同報メールがある。
これは、たとえば有料会員限定の有用な情報を送ったり、
あるいは無料会員に有料会員向けのサービスをチラ見せして有料化を促したり、
または特定の条件に沿った会員（たとえば特定の地域に住む人）にだけ送るのに使われる。

場合によってはデータベースにあるすべてのユーザに送る場合もあるし、
機械的に抽出した、特定の条件にマッチしたユーザに送る場合もあるし、
人間の手で抽出した特定ユーザのみに送る場合もある。

このようなことはBtoSに限った話ではなく、BtoBでも行われることがある。

Bccを使うと、ふつうのメールソフト（MUA）で、
受信者がお互いのアドレスがわからないようなかたちで、複数の受信者にメールを送ることができる。
そこで、簡単にBccでメールを送ることにしたのだが、
間違えてCcに全員のアドレスを設定してしまったため、受信者が、
自分の他にどのような相手に送られたかわかる状態になってしまった。

（最近だとスマートホンなどへの通知のほうが普通かもしれませんが、未だにメールもあると思いますので。）


## File 7: 大量のユーザにメールを送ったが、ブロックされていた

大量のユーザに送る一斉同報メールと似たようなものに、スパムというものがある。
要は迷惑メールである。
たいていは少し頭が悪い人を引っかけようとする詐欺メールで、
膨大なメールを送ることで収率の悪さを補う。

あるサーバから一斉同報メールを送ろうとしたが、ブロックされて届かなった。
まったく同じメールを大量のアドレスに送ったため、どうもスパムと誤判定されてしまったらしい。

（これは、どうすればいいかわからないかもしれません。でもこういうこともあると知っておいたほうがよいので入れておきました。）


## File 8: 大量のユーザにメールを送ったが、時間がかかりすぎて時間内に送り終わらなかった

人は、自分の名前で呼ばれると親近感が湧いたり、自分事だと捉えられるものである。
それはメールでも同じで、アナウンスしたい内容だけが書かれていたり、
あるいは「ユーザの皆様」と書かれていたりするよりも、
「○○様」と自分の名前やアカウント名が書かれているほうが、少しはそのメールの内容に興味を持つ。

ということで、大量のユーザにメールを送る際に一人ひとりの名前を埋め込むことにした。
その結果、同時に大量のユーザに送ることができず、
1通1通名前を入れながら送るかたちとなったので、
メールを送り終わったときには台風のピークは過ぎていた。

（メール送信というのは結構コストの高い処理で、1秒間に送れるメール数はたかが知れているのです。）


## File 9: 前回の送信を中断した結果、次の送信時に数百万人に誤送信

メール大量送信の効率化のため、あるプログラムでは、
事前に送信内容のキャッシュを作っておくことで、送信時間の短縮を図っている。
このキャッシュは、すべての送信が完了した後にクリアされるようになっている。

しかし、あるとき送信メールの内容に間違いがあるのに送信中に気づき、
`Ctrl + C`で送信処理を途中でやめた。
本文の情報を修正し、必要な確認もしてもらえたので、再度送信をした。
しかしこのとき、前の送信中断によりキャッシュが残ってしまっており、
膨大なユーザにほぼ同じ内容を2通送信することになってしまった。


## File 10: 定期的なファイルの削除が失敗していた

cronというプログラム（サービス）を使うと、特定の日や特定の時刻に特定のコマンドを実行することができる。
WNIでは、たとえば過去12時間のレーダー画像を出すコンテンツなど、
「最新のデータに加え、一定の期間のデータを保持した上で、それよりも古いデータは削除する」
というようなコンテンツが多い。
最終的にユーザの目に触れるコンテンツだけでなく、
そういったコンテンツを作るための中間データについても同じような対応が必要なケースがある。
そのようなデータは、サーバ内に蓄積しないよう、cronを用いて古いものを削除していく必要がある。

`find`というコマンドを用いると、
たとえば`find /usr/amoeba/tmp -type f -mtime +3`のようなコマンドラインで、
ある程度古いファイルをリストアップしたり、
さらに`-delete`オプションをつけることでそれらを削除したり、といったことが簡単にできる。

あるとき、そのようなコンテンツを生成しているサーバがdisk fullに近づいている、
と監視メンバーから知らされた。
サーバに入って調べてみたところ、削除すべきファイルのパスが間違っており、
日々走っているはずのクリーンアップがまったく行われていなかった。


## File 11: 定期的なファイルの削除を忘れた結果、削除に時間がかかった

あるとき、定期的に削除すべきファイルのクリーンアップを忘れているのに気づいたので、
削除することにした。

とあるディレクトリには100MBのファイルが1,000個、合計100GBできていた。
こちらはあっさりと削除できた。

別のディレクトリには100kBのファイルが500,000個、合計50GBできていた。
こちらは`ls`したらシェルから反応が返ってこなくなり、削除にも膨大な時間がかかった。
しかも時間がかかった割に容量が増えなかった。

（`rm -rf /path/to/unnecessary/dir`でディレクトリごと中身のファイルをすべて削除するのは、コマンド一発なので簡単です。でも、それとすべて一気に削除できるかどうかは別の話。）


## File 12: CGIへの大量アクセスで高負荷

地震や台風で極端な大雨になった場合など、WNIではアクセスが極端に集中するときが結構ある。
特に、大量のユーザを抱えているサービスで、そのようなことがある（WITH、DIMなど）。

とある台風の際に、あるWebサーバが応答しなくなってしまい、一部のコンテンツが画面に出なくなってしまった。
そのコンテンツを生成して返しているサーバが、HTTPリクエストに反応しなくなったためだった。
通常のSSH接続だとタイムアウトしてしまって入れない。
タイムアウトをしない設定にしてアクセスしたところ、かなりの時間をかけてようやくサーバに入れた。
`ps`コマンドを打つと、大量のCGIのプロセスが見えた。

（状況によりますが、解決策はかなりたくさんあるはずです。とはいえ、実際にはふつうは状況によって様々な制限を受けるので、常にどんな手法でも使えるわけではありません。要はケースバイケースです。）


## File 13: アプリが必要以上にAPIを叩いていた

スマートホンアプリでもWebアプリケーションでも、
必要かつ十分なデータを何らかのAPIを叩いてとってきて、
アプリケーション本体ではそのデータを気持ちよく表示するのに集中するのが一般的である。
APIを叩きにいくのにもわずかに時間がかかるので、自前でAPIを作る場合、たいていは、
1回叩けば画面の表示に必要な情報はすべて手に入るように作る。

スマートホンアプリで天気予報の情報を出すために、地点をパラメータとするHTTPリクエストを受けて予報データを返すCGIを非公開APIとしてサーバに作成し、そのAPIをスマートホンアプリから叩くようにした。
開発メンバー全員でアプリを自分の端末に入れて使い、動作確認を繰り返しながら開発を進めた。
すべては順調だった。

いざアプリをリリースしたら、膨大なユーザからのアクセスでCGIが応答不能になってしまい、
アプリの画面が真っ白になってしまった。
調べた結果、1回叩けば済むはずだったのに、プログラムの作りを間違えた結果、
1つのページの表示のために何回も同じAPIから同じデータをとってくるようになっていた。
表示側も多少遅いという問題はあったが、それよりも、API側は想定の何倍も叩かれることとなり、
負荷が増してしまった。
高々20人程度の開発メンバーでは負荷が掴めなかった。


## File 14: アプリが叩いていたのは開発系のAPIだった

スマートホンアプリで天気予報の情報をバージョンアップするために開発系でCGIを作り、
アプリからそちらのCGIを叩いて動作確認をした。
リリース時にURLを変えるのを忘れてしまい、
負荷に対して貧弱な開発系のCGIを叩くアプリがユーザに使われることとなってしまった。

さらに、新しいバージョンが出てもなかなかバージョンアップしないユーザもいるため、
開発系のCGIは修正リリース後も叩かれ続けた。


## File 15: stockサーバの負荷が高まる

社内ではNelsonというシステムで配信された過去データがstockサーバというものに保存されており、
Data Catalogからリンクで辿れる。
これを用いて、ある一定の期間の過去データはブラウザでアクセスできるようになっている。
経緯は知らないが、おそらく「比較的近い過去のデータをとってきたい」というニーズのために、
このようになったのだと思われる。

だが、IOCでもData Catalogでも開発用や運営用のWikiでも何でもそうだが、
一昔前の社内のサーバは貧弱な1台や2台のマシンが担っていることが多く、
アクセスによる負荷などはあまり考慮されていなかった。
これは、WNIが特殊なわけではなく、クラウドが普及する前は、
特に巨大企業などでなければ、世の中一般的にそうだったはずである。
大学の小さな学科などのサーバもたいていそうである。
会社というのは基本的に社外のたくさんの顧客向けにサービスをするために存在するのであり、
またDoSやDDoSなどのインターネットからの攻撃も、
会社が小さく信頼メンバーしかいないうちは、社外から仕掛けられるリスクのほうが高い。
リスクへの対策という意味では対外的なほうを重視するのは仕方がない。
社内向けに、素晴らしい見栄えの、負荷対策、セキュリティ対策バッチリのシステムを作ったところで、おそらくそのコストに見合った力は発揮できるとは思えない。

が、会社が大きくなり、メンバーが増え、色々なことをする人が増えた。
また、Wikiなどほかのサービスであれば機械的にダウンロードする人もいなかっただろうが、
保持しているのが直近の過去データだったのがよくなかった。
本来のルールでは、最新データはNelsonシステムを通じて配信するもので、
stockから最新データを機械的にダウンロードするのは禁止とされている。
しかし、配信してもらうサーバをもたないユーザは、機械的にデータをダウンロードするようになった。
そもそも、Data Catalogからリンクされていてダウンロード可能なのは事実である。
過去データの需要も高まり、その一方でstockの機能に取って代われるほどのサービスは、
未だに存在しない。
というわけで、stockはたまにアクセス負荷が増して応答が鈍くなり、
D-Centerがアクセス元を探したり、帯域制限やsleepの使用を呼びかけたりするようになった。

（この問題から考えるべきことは膨大にあります。という意味でくどい記述となっています。）


## File 16: stockサーバからデータをとるときにひたすらCGIをwgetした

WNIでは社内データフォーマットとしてRUというものを用いており、
stockに含まれる多くのデータがRUであるが、
RUはバイナリフォーマットなのでブラウザで表示できない。
ということで、stockには、本来のファイルのダウンロードのリンクと並んで、
CGIでRUの内容を表示（ダンプ）できるリンクが存在する。
人によっては、stockからファイルをダウンロードしようとして、
誤ってこちらのCGIを叩いてしまうことがある。


## File X1: 10日間 で AWS Lambda 関数を 28億回 実行した話

[10日間 で AWS Lambda 関数を 28億回 実行した話](https://blog.mmmcorp.co.jp/blog/2019/12/25/lambda-cloud-bankruptcy/)

（社外編ということで、[本番環境でやらかしちゃった人 Advent Calendar 2019](https://qiita.com/advent-calendar/2019/yarakashi-production)の25日目の記事です。このAdvent Calendarは、当初の期待ほど（そしておそらく当初の作成者の意図よりも）質が高くなくて残念ではありますが、真面目にミスと再発防止策を書いてくれているこの記事はよいですね。）
