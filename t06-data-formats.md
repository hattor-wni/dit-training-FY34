# 継続トレーニング #6：さまざまなデータフォーマットとファイル操作

## 概要

今回と次回はさまざまなデータフォーマットとファイル操作のお話をします。
プログラミングで行うことは細かく分ければ様々ですが、アプリケーションを作る場合、
ほとんどはデータを別のデータ（画像、テキストメッセージ、数値の集計結果など）に
変換することだといえます。
そういう意味で、データの読み込みと書き出しは最も大切な処理の一つです。
業務でよく触るデータフォーマットは限られているので、
それらのデータフォーマットの特徴などに関する知識をつけながら、
読み込んで処理できる（フォーマットによっては書き出しもできる）ようになること
を目指します。

第4回で「インタフェース」について話をしましたが、
データフォーマットも取り決められた規格なので、インタフェースです。
処理とは切り離されており、道具（プログラミング言語など）の選択は自由ですが、
このトレーニングでの方針に従い、例としては主にPythonやJavaScriptを扱います。

### 本日お話すること

* はじめに：入出力は重要！
* さまざまなデータフォーマット
  * テキストデータとバイナリデータ
* ファイル操作
  * 開く際のモード
  * 開けるファイル数の上限
  * ファイルディスクリプタ
  * 「閉じる」の徹底
  * バッファリングとflush
* プレーンテキスト（テキストファイル全般）
  * 行単位での読み込みと書き出し
  * 改行の除去、空行処理
  * 改行コード
* JSON
  * フォーマットの仕様
  * JSONで扱える型
  * jqコマンド
  * Pythonでの読み込み、書き出し
* CSV
  * CSVの多様性
  * Pythonでの読み込み
* データフォーマットに含まれるフォーマット
  * 日時
  * 経緯度
  * 色
* 次回予定
  * XML
    * SGML、HTML、XML
    * DOM
    * XPath
    * さまざまなXML
      * KML
      * SVG
  * RU
  * フラットバイナリ
  * GRIB2
  * さまざまな画像フォーマット
    * PNM
    * PNG、GIF
    * JPEG
    * SVG
  * 圧縮形式
    * gzip
    * bzip2
    * xz
  * ファイルシステムでの操作（globなど）
  * tar


## はじめに：入出力は重要！

プログラミングで実現したいことの多くはこんな感じだと思う。

* 定型的な作業を自動化する
* データやリソースを管理する
* 大量の数値演算を行う（数値シミュレーション、機械学習）
* データの変換（集計や可視化も含む）をする

データの変換をする上では必ずデータを読み込み、出力しなければならない。
すなわち、人間の解釈を挟まずに機械が読めるかたちでの入出力が必要となる。
その入出力に用いられるのがファイルであり、
人間の解釈を挟まないために使われているのがファイルフォーマットという「規格」（インタフェース）である。
APIについて理解していれば、このあたりの話はすんなりと受け入れられるはず。


## テキストファイルとバイナリファイル

テキストファイルとバイナリファイルが存在する。
そのことは知っているはずなので、簡潔に述べる。

* テキストファイルのよいところは、人間が読み書きしやすいところ。
  人間が読み書きする必要のあるデータに適している。
  また、たとえ直接読み書きしないとしても、
  データをプログラムで処理するときにデバッグはつきもので、
  そのときにデータの中身を確認するのは当然である。
  パッと見て理解できるほうがデバッグも楽だ。
* バイナリファイルのよいところは、効率がよいところ。
  たとえば32ビットの数字の最大値4,294,967,296 (4G) は10桁なので、
  「4294967296」という10進数を書いたテキストファイルとして保存すれば10バイトとなる。
  これに対してバイナリファイルとすれば 32 / 8 = 4バイトとなる。
  1つの数値なら大したことないが、このような数値が1,000,000個並んでいるようなデータの場合、
  その差は大きい。

## ファイル操作

◆注記：
Pythonでの操作の説明はウェブ上に山のようにあるので、なるべく一般的な説明のみにとどめる。
書籍を参照する場合、[『入門 Python 3』](https://www.oreilly.co.jp/books/9784873117386/)なら8.1を読むとよい。

ファイルは、ふつう、

1. ファイルを開く
2. ファイルから読み込む、または書き出す
3. ファイルを閉じる

という手順で読み書きする。

例：[t06/src/open-sample-1.py]
（ただし、with文を使った後述の例の記法が推奨。）

### 開く際のモード

開く際にはモードを指定する。
モードは、下記の組み合わせである。

* 操作：基本的には、読み出し or 書き込み or 追記
  * 書き込みは、「ファイルが存在する場合は上書き」と
    「ファイルが存在しない場合のみ（新規作成）」とある
  * 読み書き両用もある
* タイプ：テキストかバイナリか

なお、「読み出し」「テキスト」はデフォルトなので、上の例では指定していない。

### 開けるファイル数の上限

一度に開けるファイルの数には上限があるので、使い終わったら必ず閉じる。
プログラムの実行が終われば自動的に閉じられるが、
デーモンのように実行が終わらない場合は勝手には閉じない。
なので、「必ず閉じる」を徹底する。

ちなみに同時に開けるファイル数（ファイルディスクリプタ数）の上限値は`ulimit`コマンドで確認や変更ができる（ここで変更できる上限値はこのシェルについての設定値なので、たとえ0にしてもシステムには影響しないので大丈夫）。

```
noritada[20:28]%  ulimit -n
2560
noritada[20:28]%  ulimit -n 0
noritada[20:28]%  ulimit -n
0
noritada[20:28]%  echo hogehoge > hogehoge.txt
zsh: too many open files: hogehoge.txt
noritada[20:28]%
```

### ファイルディスクリプタ

ファイルの読み込みや書き込みのコードはPythonでは次のように書くが、
このように`open()`によって生成されるオブジェクト`f`を、
Pythonの世界ではファイルオブジェクトと呼ぶ。
言語によって呼び方は異なるが、
いずれもファイルディスクリプタという一般的な概念を抽象化したものである。

言葉はすぐに覚えなくてもよいのだが、大事なのは、
**この変数が「開いたファイルの中のどこに今いるか」を表す**、ということ。
開いたときは（追記モードなどでなければ）先頭にいるし、
テキストファイルで1行読み込めば1行進んだ位置にいる。
バイナリファイルで1バイト読み込めば1バイト進んだ位置にいる。
そのイメージを持てれば、ファイルの中を自由自在に読めるはず。

```
f = open(filename)
f.read()
f.close()

f = open(filename, 'w')
f.write('hogehoge')
f.close()
```

### 「閉じる」の徹底

ここはPython限定の話。

Pythonでは、with文とコンテキストマネージャという仕組みを使うと、
with文のブロックから出るときに必ず終了処理が走るようにすることができる。
これを用いて、`with open()`で開いたブロックから出るときには
必ず`close()`が呼び出されるように作られているため、
with文を使って`open()`するのが安全である。

何を言っているのかわからなくても、とりあえず`with open()`で書く、と覚えておく。

例：[t06/src/open-sample-2.py]

◆参考：
[リファレンスマニュアル 8.5 with文](https://docs.python.org/3/reference/compound_stmts.html#the-with-statement)

### バッファリングとflush

まず、いつかきちんと話をする時間を作りたいと思っているが、
メモリへの読み書きの速度に比べると、入出力の速度というのは圧倒的に遅い。
標準出力に書き出すのも遅いし、SSDに書き出すのも遅ければ、
HDDに書き出すのなんてすさまじく遅い。

したがって、たとえば「1文字書き出す」のを10000回するよりも、
書き出す内容をメモリ上に溜めておいて、10000文字を一気に書き出したほうが効率がよい。
読み込みも同様で、1文字読むなら最初にある程度まとめて読んでメモリ上に溜めておいたほうがよい。
このようなやりかたをバッファリングという。

言語によってはバッファリングなしのインタフェースをバッファリング用のインタフェースでwrapするようになっているが、
Pythonの場合、`print()`や`f.write()`のような基本的な関数でさえバッファリングするようになっている。

バッファリングは、特に書き出しのときに意図しない挙動を引き起こしうる。
「`print()`や`write()`したのに書き出されない」という現象だ。
書き出されないのはバッファに残ってしまっているためである。
バッファに残ってしまっているデータを吐き出させるのをflushといい、
Pythonだと`f.flush()`や`print()`の`flush`オプションでできる。

なお、一般に、ファイルを閉じるときには必ずflushされるので、
書き込んですぐにファイルを閉じ、その間に誰もファイルにアクセスしないようなケースでは、
気にしなくてよい。
また、Pythonでは標準出力に`print()`する場合、
改行が含まれているとflushされるようなので（要出典）、
そのような場合も気にしなくてよい。

以前鈴木元気さんが「途中までしか出力されないんですが……」と質問に来たとき、
何も見ずに瞬間的にflushの問題だと答えられたくらい、
プログラミング歴の長い人は必ず経験する問題である。

ハンズオン：
* 演習1：バッファリングとflushを感じてみる（print()編）
* 演習2：バッファリングとflushを感じてみる（write()編）

## プレーンテキスト（テキストファイル全般）

プレーンテキストとは、
プログラムで処理しやすいフォーマットになっていない、単なるテキストファイルである。
たとえばテキストエディタにちょっとしたメモを書き殴って保存したらそれはプレーンテキストだし、
世の中の適当なメールの本文をファイルに保存したら、おそらくそれもプレーンテキストになる。
なので、フォーマットは様々で、プレーンテキスト独自の処理というものは特にない。

知らない人の作ったプレーンテキストを読み込むことは普通はないが、
ちょっとした処理をした結果を一時的に自分の好きなフォーマットのプレーンテキストとして保存しておいて、
後で別のプログラムから読み出す、ということはよくあるので、
以下の操作や知識は持っているとよい。

### 行単位での読み込みと書き出し

プレーンテキスト（に限らずテキストファイル全般）後述するJSONやXMLを除けば、テキストファイルを処理する場合、
「1行目は無視する」「`#`で始まっている行は無視する」など、
行単位で処理することが多い。
なので、どんな言語でもだいたい次のような読み込みメソッドが用意されており、
これらが使えるようになっておけばよい。

* 今いる場所から1行読み込む
* 今いる場所から後のすべてを1つの文字列データとして読み込む
* 今いる場所から後のすべてを行ごとのリストとして読み込む

書き出しに関しても同様に、行単位で書き出したり、
すでに改行コードを含んでいるものをまとめて書き出したりすることが多い。
そのため、以下のようなことができればよい。

* 文字列の末尾に改行を加えて書き出す
* 文字列の末尾に改行を加えずに書き出す

### 改行の除去、空行処理

上で「1行読み込む」と述べたが、1行読み込んだ場合、
ふつうの言語では末尾に改行がついた文字列データが手に入る。
その文字列データをそのまま`print()`すると、
`print()`は末尾に改行をつけて印字するため、改行が2つついて表示される。
したがって、次のこともできたほうがよい。

* 行末の改行の除去

また、「`#`で始まっている行は無視する」「空行で分割する」など、
行の中身が特定のパターンにマッチするかで条件分岐をすることが多い。
したがって、下記もできてほしい。

* 正規表現や部分文字列を用いたパターンマッチング

ハンズオン：
* 演習3：1行目を無視するプログラム
* 演習4：コメント行を除去するプログラム
* 演習5：最初に現れる空行までを無視するプログラム

### 改行コード

なお、上で「改行」とひとくくりにしたが、
改行コードはCR（`0x0D`）、LF（`0x0A`）、CR+LFがあり、
OSによってそれぞれ使われているコードが異なる。
なので、CR+LFを使うWindowsで作ったファイルを、LFを使うUnixに持っていった場合、
エディタで開くと改行前に余計な文字(`0x0A`)が表示されてしまう、というようなことがある。

だが、Pythonでファイルを開いて読む場合、どちらも改行として認識した上で、
勝手に`'\n'`に置き換えてくれる。
また、書き出す文字列に`'\n'`と入れておけば、この改行文字を、
インストールされているシステムに合った改行コード（CR or LF or CR+LF）に変換した上で出力してくれる。
したがって、改行コードで悩むことはあまりなく、改行を入れたければ`'\n'`のみを使えばよい。

CやJavaのプログラムを書いてきた人にとっては、CR = `'\r'`、LF = `'\n'`で、
それらの使い分けが必要であったが、Pythonでは基本的にそれは必要ない。

が、「Windowsで作ったファイルをUnixのPythonで読み込んでそのまま書き出す」などということをすると、改行コードだけすべて書き換わってしまうので、注意が必要である。

◆参考：["改行コード" in Wikipedia](https://ja.wikipedia.org/wiki/%E6%94%B9%E8%A1%8C%E3%82%B3%E3%83%BC%E3%83%89)


## JSON

言わずとしれた、現在フロントエンドで最も使われているデータフォーマット。
JavaScriptのサブセット。

メリット：
* JavaScriptから扱いやすい
* Pythonの辞書にも似ている記法
* 読みやすい
* 型がある
* シンプルながらポイントは押さえている


### フォーマットの仕様

フォーマットの仕様は慣れないと読みにくいかもしれないが、
JSONの場合はシンプルでわかりやすいので、触れておく。

https://www.json.org に、絵も交えてわかりやすく描かれている。

```
json
    element

value
    object
    array
    string
    number
    "true"
    "false"
    "null"

object
    '{' ws '}'
    '{' members '}'

members
    member
    member ',' members

member
    ws string ws ':' element

array
    '[' ws ']'
    '[' elements ']'

elements
    element
    element ',' elements

element
    ws value ws

string
    '"' characters '"'

characters
    ""
    character characters

character
    '0020' . '10ffff' - '"' - '\'
    '\' escape

escape
    '"'
    '\'
    '/'
    'b'
    'f'
    'n'
    'r'
    't'
    'u' hex hex hex hex

hex
    digit
    'A' . 'F'
    'a' . 'f'

number
    integer fraction exponent

integer
    digit
    onenine digits
    '-' digit
    '-' onenine digits

digits
    digit
    digit digits

digit
    '0'
    onenine

onenine
    '1' . '9'

fraction
    ""
    '.' digits

exponent
    ""
    'E' sign digits
    'e' sign digits

sign
    ""
    '+'
    '-'

ws
    ""
    '0020' ws
    '000D' ws
    '000A' ws
    '0009' ws
```

たとえば数値のところはこう読む。

```
number # 数値
    integer fraction exponent # 整数部分＋小数点および小数部分（空文字にもなりうる）＋指数部分（空文字にもなりうる）

integer # 整数
    digit # 数字1文字
    onenine digits # 1-9までの数字1文字＋数字の羅列
    '-' digit # マイナス記号＋数字1文字
    '-' onenine digits # マイナス記号＋数字1文字＋数字の羅列

digits # 数字の羅列
    digit # 数字1文字
    digit digits # 数字2文字以上

digit # 数字1文字
    '0'
    onenine

onenine # 1から9までの数字1文字
    '1' . '9'
```

つまり、正の整数は1から9までの数字で始まっていないといけない。
たとえば `0123` というのは、JSONの仕様を犯していることがわかる。
また `+123` という、「正」を明記した表記もダメだとわかる。


### JSONで扱える型

「型がある」のはよいと[第4回](t04-http-webapi-rest.md)でも軽く述べた。
テキストファイルのデータフォーマットであれば、
どんなフォーマットでも文字列は表現できるだろうが、
文字列から数値などに一々変換が必要なのと、読み込み時に型まで含めて読み込めるのでは、
便利さが違う。

JSONでは下記の型を使用することができる。

* 文字列 (`"abc"`)
* 数値 (`123`, `1.2`, `1.2e3` など)
* ヌル値 (`null`)
* 真偽値 (`true`, `false`)
* オブジェクト (`{ 'key1': 'value1', 'key2': 'value2' }`)
* 配列 (`[1, 2, 3]`)


### jqコマンド

JSONのちょっとした処理をするのにPythonなどの汎用的なプログラミング言語を使う必要はない（使ってもよい）。
`jq`コマンドを使うと、ちょっとした抽出や整形が簡単にできる。

◆参考：[jq コマンドを使う日常のご紹介](https://qiita.com/takeshinoda@github/items/2dec7a72930ec1f658af)

```
noritada[8:48]%  echo '[{"name": "apple", "order": {"price": 100, "amount": 5}}, {"name": "orange", "order": {"price": 50, "amount": 20}}]' | jq '.[] | {"name": .name, "amount": .order.amount}'
{
  "name": "apple",
  "amount": 5
}
{
  "name": "orange",
  "amount": 20
}
```

実用的である。

```
noritada[8:50]% aws ce get-cost-and-usage --profile expo-legacy --time-period Start=2019-10-01,End=2019-11-01 --granularity MONTHLY --metrics UnblendedCost --group-by Type=DIMENSION,Key=SERVICE | jq -r '.ResultsByTime[].Groups[] | [(.Keys[]), .Metrics.UnblendedCost.Amount] | @csv' | head
"AWS CloudTrail","131.712189"
"AWS CodePipeline","3"
"AWS Config","70.923"
"AWS Glue","0"
"AWS Key Management Service","2.009128968"
"AWS Lambda","183.3469381427"
"AWS Secrets Manager","3.7746642424"
"AWS Security Hub","11.389"
"AWS Step Functions","0"
"AWS WAF","34.942498426"
```


### Pythonでの読み込み、書き出し

https://docs.python.org/ja/3/library/json.html

* 変数に含まれた文字列からの読み込み（JSONを表す文字列からの変換）：`json.loads()`
* ファイルオブジェクトからの読み込み：`json.load()`
* 文字列への書き出し（JSON文字列への変換）：`json.dumps()`
* ファイルオブジェクトへの書き出し：`json.dump()`

```
import json

json_str = '[{"hoge": 1000, "fuga": 2000}]' # ここでは仮として直接代入しているが、ネットワーク経由でデータの中身を変数に代入した場合も含めて考えればよい
json_obj = json.loads(json_str)
json_obj.hoge # => 1000
```


## CSV

CSVは、データの分析や可視化をしたことがあれば使ったことがあるはず。
Excelなどのスプレッドシートアプリケーションでも基本的にインポートやエクスポートがサポートされている。

### CSVの多様性

CSVは、シンプルなものであれば「ファイルの各行を`','`で`split()`してあげる」で読み込める……はずである。
それくらいのコードであればすぐに書けるはず。
しかし、世の中のCSVは非常に多様である。

* 1行目がヘッダ行になっている or ヘッダ行なしでいきなり値の行が始まっている
* 冒頭に無視したい余計な行が存在する
* 列の数が異なる行が存在する
* 日時として処理したいが、色々なケースがある
  * 年、月、日がすべてバラバラのカラムとなっている
  * 年月日と時刻でカラムがわかれている
  * 日時で1つのカラムとなっている
* カラムの区切り文字が`","`以外、たとえばタブ文字`"\t"`やセミコロン`";"`だったりする
* 各カラムがダブルクォーテーションマークで囲まれており、クォート内にカンマが含まれている

これらのさまざまなケースに対応するためには、CSV読み込み用のモジュールを使ったほうがよい。


### Pythonでの読み込み

CSVの読み込みは、Python標準ライブラリの[csvモジュール](https://docs.python.org/ja/3/library/csv.html)を使う。
もしデータサイエンティスト向けのライブラリ、pandasがインストールされているのであれば、
[pandas.read_csv()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)で高速に読み込める。


## 余談：「実在」しないファイル

一般ユーザが認識する「ファイル」は、
macOSならFinder、WindowsならExplorerを開くと見られるもの、
Unixなら`ls`を叩くと名前が表示されるもので、
それらは基本的にHDDやSSDなどの物理デバイスに書き込まれている、と思うかもしれない。
しかしこれは必ずしも正しくない。

FinderやExplorerや`ls`で見えていても、実際に存在しないファイルもある。
たとえばLinuxで`ls /proc`を打つと、たとえばこんな結果が出てくる。

```
koba-n[18:33]%  ls /proc
1      1106   1189  1204   1286  1328	143    154    170    17416  18037  185	203    20561  20579  22     29064  312	  41	6     76   896	96	   devices	kpagecgroup   stat
10     1107   119   1217   1287  134	14313  155    17082  17495  18038  186	204    20562  206    220    29130  313	  4261	61    77   897	967	   diskstats	kpagecount    swaps
100    1108   1190  122    129	 135	144    1558   171    176    18039  188	205    20563  20609  23     29184  31408  43	626   78   9	976	   dma		kpageflags    sys
1000   11095  1191  1224   1295  13541	14436  156    17121  17667  18040  189	20546  20564  207    232    29387  315	  44	627   8    90	98	   driver	loadavg       sysrq-trigger
1001   111    1192  123    13	 13587	14506  15748  17142  177    18041  19	20547  20565  2075   25     29441  316	  45	628   80   901	980	   execdomains	locks	      sysvipc
1002   1112   1193  124    130	 13599	146    158    172    17741  18050  190	20548  20566  2076   26     29443  317	  46	629   81   902	982	   fb		meminfo       thread-self
101    112    1194  125    1308  136	14635  159    17206  178    18051  191	20549  20567  209    263    298    31903  47	63    82   909	989	   filesystems	misc	      timer_list
102    1126   1195  1256   131	 13674	147    16     17217  17865  18098  192	20550  20568  21     27     299    32	  49	64    83   918	99	   fs		modules       tty
1023   113    1196  126    1318  137	14709  160    17221  17866  18100  194	20551  20569  210    28     3	   320	  5	65    84   92	991	   interrupts	mounts	      uptime
1027   114    1197  1260   1319  138	1473   161    17259  17867  18101  195	20552  20570  21033  28694  300    323	  50	66    86   929	994	   iomem	mtrr	      version
104    1142   1198  1263   132	 1384	1479   162    17277  17868  18107  196	20553  20571  211    28738  30391  325	  51	68    87   93	acpi	   ioports	net	      vmallocinfo
105    116    1199  1271   1321  13878	148    164    17291  17890  18108  197	20554  20572  212    28748  307    33	  52	69    88   930	buddyinfo  ipmi		pagetypeinfo  vmstat
106    117    12    128    1322  13930	149    1643   173    17893  18110  198	20555  20573  213    28751  30745  34	  53	70    89   931	bus	   irq		partitions    zoneinfo
107    118    120   1282   1323  1395	15     165    17343  179    18118  2	20556  20574  214    28758  308    35	  55	71    891  94	cgroups    kallsyms	sched_debug
108    1180   1200  12826  1324  14	150    166    17348  180    18119  20	20557  20575  215    28766  31	   37	  56	7131  892  944	cmdline    kcore	schedstat
11     11841  1201  1283   1325  140	152    167    174    18026  182    200	20558  20576  216    28827  310    38	  57	72    893  945	consoles   key-users	self
110    1187   1202  1284   1326  141	1528   168    17413  18035  183    201	20559  20577  218    29     31018  39	  58	74    894  95	cpuinfo    keys		slabinfo
11040  1188   1203  1285   1327  142	153    17     17415  18036  184    202	20560  20578  219    29011  311    40	  59	75    895  956	crypto	   kmsg		softirqs
```

しかしこれらのファイルは、実はHDDやSSDといった物理デバイスの上には「実在」しない。
これらはいずれもOSがメモリ上に作り出した仮想のファイルシステム上のファイルで、
数字のファイル（`/proc/1`などのディレクトリ）はその番号（pid）のプロセスの情報を格納している（説明を端折ったが、ディレクトリもファイルの一種）。
また、`/proc/cpuinfo`や`/proc/meminfo`などはCPUやメモリの使用状況を格納している。

```
koba-n[18:32]%  head /proc/meminfo
MemTotal:       65863552 kB
MemFree:          661152 kB
MemAvailable:   64685416 kB
Buffers:           65108 kB
Cached:         63526328 kB
SwapCached:         2708 kB
Active:         55136636 kB
Inactive:        8465092 kB
Active(anon):      26620 kB
Inactive(anon):    28776 kB
koba-n[18:32]%
koba-n[18:44]%  ls /proc/18108
attr	   cgroup      comm		cwd	 fd	  io	    map_files  mountinfo   net	      oom_adj	     pagemap	  root	     sessionid	stack  status	timers	       wchan
autogroup  clear_refs  coredump_filter	environ  fdinfo   limits    maps       mounts	   ns	      oom_score      personality  sched      setgroups	stat   syscall	timerslack_ns
auxv	   cmdline     cpuset		exe	 gid_map  loginuid  mem        mountstats  numa_maps  oom_score_adj  projid_map   schedstat  smaps	statm  task	uid_map
koba-n[18:44]%  ls -l /proc/18108/cwd
lrwxrwxrwx 1 koba-n devel 0 11月 28 18:43 /proc/18108/cwd -> /home/koba-n
koba-n[18:45]%  cat /proc/18108/environ
LANG=ja_JP.UTF-8USER=koba-nLOGNAME=koba-nHOME=/home/koba-nPATH=/usr/local/bin:/usr/bin:/bin:/usr/gamesMAIL=/var/mail/koba-nSHELL=/usr/bin/zshSSH_CLIENT=172.16.240.134 54494 22SSH_CONNECTION=172.16.240.134 54494 172.16.248.99 22SSH_TTY=/dev/pts/0TERM=xterm-256colorXDG_SESSION_ID=8777XDG_RUNTIME_DIR=/run/user/31395%
```

（これらはOSレベルの話でアプリケーションプログラミングとは無縁そうに見えるが、
こういったメモリ上のファイルシステムをうまく使えば、
HDDへの低速な書き込みをせずに「ファイル」への書き込みを実現できるので、
場合によっては有用である。）

こういったメモリ上のファイルシステムのファイルについても、
今回説明した方法でまったく同様にプログラムからアクセスできる。
（ただし、root権限がないとアクセスできないファイルは当然ながらアクセスできない。）
